name: Daily Data Fetch

on:
  schedule:
    # Runs at 00:00 UTC every day
    - cron: '0 14 * * *'
  # Allow manual trigger
  workflow_dispatch:

jobs:
  fetch-data:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential python3-dev gcc
    
    - name: Install dependencies
      working-directory: ./bk
      run: |
        python -m pip install --upgrade pip
        pip install wheel setuptools
        pip install --only-binary :all: greenlet==3.1.1
        pip install -r requirements.txt
        pip install boto3
        
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
        
    - name: Fetch new data
      working-directory: ./bk
      env:
        API_KEY: ${{ secrets.API_KEY }}
      run: |
        python scripts/get_data.py
        
    - name: Upload data to S3
      working-directory: ./bk
      run: |
        # Upload timestamped files
        for file in data/*_data_*.json; do
          if [ -f "$file" ]; then
            aws s3 cp "$file" "s3://${{ secrets.AWS_S3_BUCKET }}/data/$(basename "$file")"
          fi
        done
        # Upload latest files
        for file in data/*_latest.json; do
          if [ -f "$file" ]; then
            aws s3 cp "$file" "s3://${{ secrets.AWS_S3_BUCKET }}/data/$(basename "$file")"
          fi
        done